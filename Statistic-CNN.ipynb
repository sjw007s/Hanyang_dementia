{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb42d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from functools import partial\n",
    "from typing import Any, Callable, List, Optional, Type, Union\n",
    "import os\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import random\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import nn\n",
    "import sklearn.metrics\n",
    "import matplotlib\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_name = 'F' #E\n",
    "if device_name == 'F':\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5\n",
    "\n",
    "class Data_load:\n",
    "    def __init__(self,num):\n",
    "        self.len_=0\n",
    "        self.x_data_name=[]\n",
    "        self.x_data_test_name=[]\n",
    "        self.normal_size=0\n",
    "        self.mci_size=0\n",
    "        self.ad_size=0\n",
    "        self.test_len=0\n",
    "        list_disease = ['Normal', 'MCI', 'AD']\n",
    "        for i in range(num,num+1,1):\n",
    "            for label_target, j in enumerate(list_disease):\n",
    "                part_data_name=[]\n",
    "                path = device_name+\":/k-fold validation/\"+str(i)+\"/\"+str(j)+\"/\"\n",
    "                dir_list = os.listdir(path)\n",
    "                len_dir=len(dir_list)\n",
    "                for k in range(len_dir):\n",
    "                    part_data_name.append([path+dir_list[k], label_target])\n",
    "                self.x_data_test_name.append(part_data_name)\n",
    "                if label_target == 0:\n",
    "                    self.normal_size = len_dir\n",
    "                elif label_target == 1:\n",
    "                    self.mci_size = len_dir\n",
    "                else:\n",
    "                    self.ad_size = len_dir\n",
    "                self.test_len+=len_dir\n",
    "                        \n",
    "        self.final_data_test_name=[]\n",
    "        for i in range(len(self.x_data_test_name)):\n",
    "            for j in range(len(self.x_data_test_name[i])):\n",
    "                self.final_data_test_name.append(self.x_data_test_name[i][j])\n",
    "        \n",
    "    def out(self):\n",
    "        return self.final_data_test_name\n",
    "\n",
    "def training(data, batch_size):\n",
    "    batch_total = len(data)//batch_size\n",
    "    batch_na = len(data)%batch_size\n",
    "    for i in range(batch_total+1):\n",
    "        x_data=[]\n",
    "        y_data=[]\n",
    "        extra = []\n",
    "        extra_final = []\n",
    "        if i == batch_total:\n",
    "            if batch_na == 0:\n",
    "                break\n",
    "            else:\n",
    "                temp_data = data[i*batch_size:] \n",
    "        else:\n",
    "            temp_data = data[i*batch_size:(i+1)*batch_size]\n",
    "        for j in range(len(temp_data)):\n",
    "            img = nib.load(temp_data[j][0]+'/1/final/1_t1_final.mnc').get_fdata() \n",
    "            img = 255*img/img.max() \n",
    "\n",
    "            x_data.append(img)      \n",
    "            \n",
    "            if temp_data[j][1] == 0:  \n",
    "                y_data.append([1,0,0])\n",
    "            elif temp_data[j][1] == 1:\n",
    "                y_data.append([0,1,0]) \n",
    "            elif temp_data[j][1] == 2: \n",
    "                y_data.append([0,0,1])  \n",
    "    \n",
    "\n",
    "        x_data = torch.from_numpy(np.array(x_data)[:,np.newaxis,:,:,:]).type(torch.FloatTensor).to(\"cuda\")\n",
    "        y_data = torch.from_numpy(np.array(y_data)).type(torch.FloatTensor).to(\"cuda\")\n",
    "\n",
    "        yield (x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26397a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Conv3d(1,64,5,stride=2)\n",
    "        self.layer_2 = nn.MaxPool3d(3)\n",
    "        self.layer_3 = nn.Conv3d(64,128,3,stride=2)\n",
    "        self.layer_4 = nn.MaxPool3d(3)\n",
    "        self.layer_5 = nn.Conv3d(128,256,3,stride=1)\n",
    "        self.layer_6 = nn.Linear(3072,3)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lrelu(self.layer_1(x))\n",
    "        x = self.layer_2(x)\n",
    "        x = self.lrelu(self.layer_3(x))\n",
    "        x = self.layer_4(x)\n",
    "        x = self.lrelu(self.layer_5(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer_6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_final_pred=[]\n",
    "total_final_y=[]\n",
    "\n",
    "total_accuracy_sum=[]\n",
    "\n",
    "total_precision = []\n",
    "total_recall = []\n",
    "total_specificity=[]\n",
    "total_q = []\n",
    "total_w = []\n",
    "total_e = []\n",
    "\n",
    "total_precision1 = []\n",
    "total_recall1 = []\n",
    "total_specificity1=[]\n",
    "total_q1 = []\n",
    "total_w1 = []\n",
    "total_e1 = []\n",
    "\n",
    "total_precision2 = []\n",
    "total_recall2 = []\n",
    "total_specificity2=[]\n",
    "total_q2 = []\n",
    "total_w2 = []\n",
    "total_e2 = []\n",
    "\n",
    "for tt in range(1,6,1):\n",
    "    model = torch.load('./3D_CNN_'+str(tt)+'.pt', map_location='cuda:0')\n",
    "    data = Data_load(tt)\n",
    "    X_test = data.out()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        final_pred=[]\n",
    "        final_y=[]\n",
    "\n",
    "        accuracy_sum=0\n",
    "        \n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        specificity=0\n",
    "        q = 0\n",
    "        w = 0\n",
    "        e = 0\n",
    "\n",
    "        precision1 = 0\n",
    "        recall1 = 0\n",
    "        specificity1=0\n",
    "        q1 = 0\n",
    "        w1 = 0\n",
    "        e1 = 0\n",
    "\n",
    "        precision2 = 0\n",
    "        recall2 = 0\n",
    "        specificity2=0\n",
    "        q2 = 0\n",
    "        w2 = 0\n",
    "        e2 = 0\n",
    "        \n",
    "        for batch, (X, y) in enumerate(training(X_test,batch_size)):\n",
    "            pred = model(X)\n",
    "            pred_softmax = F.softmax(pred,dim=1)\n",
    "     \n",
    "            for i in range(y.shape[0]):\n",
    "                final_pred.append(pred_softmax[i].to('cpu').numpy())\n",
    "                final_y.append(y[i].to('cpu').numpy())\n",
    "\n",
    "            for i in range(y.shape[0]):\n",
    "                if torch.argmax(y[i], dim=0) == 0:\n",
    "                    if torch.argmax(pred[i], dim=0) == 0:\n",
    "                        accuracy_sum+= 1\n",
    "                elif torch.argmax(y[i], dim=0) == 1:\n",
    "                    if torch.argmax(pred[i], dim=0) == 1:\n",
    "                        accuracy_sum+= 1\n",
    "                elif torch.argmax(y[i], dim=0) == 2:\n",
    "                    if torch.argmax(pred[i], dim=0) == 2:\n",
    "                        accuracy_sum+= 1\n",
    "\n",
    "                if torch.argmax(y[i], dim=0) == 0:\n",
    "                    q+=1\n",
    "                    if torch.argmax(pred[i], dim=0) == 0:\n",
    "                        recall += 1\n",
    "                if torch.argmax(pred[i], dim=0) == 0:\n",
    "                    w+=1\n",
    "                    if torch.argmax(y[i], dim=0) == 0:\n",
    "                        precision +=1\n",
    "                if torch.argmax(y[i], dim=0) != 0:\n",
    "                    e+=1\n",
    "                    if torch.argmax(pred[i], dim=0) != 0:\n",
    "                        specificity +=1\n",
    "\n",
    "                if torch.argmax(y[i], dim=0) == 1:\n",
    "                    q1+=1\n",
    "                    if torch.argmax(pred[i], dim=0) == 1:\n",
    "                        recall1 += 1\n",
    "                if torch.argmax(pred[i], dim=0) == 1:\n",
    "                    w1+=1\n",
    "                    if torch.argmax(y[i], dim=0) == 1:\n",
    "                        precision1 +=1\n",
    "                if torch.argmax(y[i], dim=0) != 1:\n",
    "                    e1+=1\n",
    "                    if torch.argmax(pred[i], dim=0) != 1:\n",
    "                        specificity1 +=1\n",
    "\n",
    "                if torch.argmax(y[i], dim=0) == 2:\n",
    "                    q2+=1\n",
    "                    if torch.argmax(pred[i], dim=0) == 2:\n",
    "                        recall2 += 1\n",
    "                if torch.argmax(pred[i], dim=0) == 2:\n",
    "                    w2+=1\n",
    "                    if torch.argmax(y[i], dim=0) == 2:\n",
    "                        precision2 +=1\n",
    "                if torch.argmax(y[i], dim=0) != 2:\n",
    "                    e2+=1\n",
    "                    if torch.argmax(pred[i], dim=0) != 2:\n",
    "                        specificity2 +=1\n",
    "\n",
    "        total_final_pred.append(final_pred)\n",
    "        total_final_y.append(final_y)\n",
    "        total_accuracy_sum.append(accuracy_sum)\n",
    "        total_precision.append(precision)\n",
    "        total_recall.append(recall)\n",
    "        total_specificity.append(specificity)\n",
    "        total_q.append(q)\n",
    "        total_w.append(w)\n",
    "        total_e.append(e)\n",
    "        total_precision1.append(precision1)\n",
    "        total_recall1.append(recall1)\n",
    "        total_specificity1.append(specificity1)\n",
    "        total_q1.append(q1)\n",
    "        total_w1.append(w1)\n",
    "        total_e1.append(e1)\n",
    "        total_precision2.append(precision2)\n",
    "        total_recall2.append(recall2)\n",
    "        total_specificity2.append(specificity2)\n",
    "        total_q2.append(q2)\n",
    "        total_w2.append(w2)\n",
    "        total_e2.append(e2)\n",
    "        \n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_accuracy = []\n",
    "\n",
    "total_normal_sensitivity = []\n",
    "total_normal_precision = []\n",
    "total_normal_specificity = []\n",
    "total_normal_F1 = []\n",
    "total_mci_sensitivity = []\n",
    "total_mci_precision = []\n",
    "total_mci_specificity = []\n",
    "total_mci_F1 = []\n",
    "total_ad_sensitivity = []\n",
    "total_ad_precision = []\n",
    "total_ad_specificity = []\n",
    "total_ad_F1 = []\n",
    "total_macro_sensitivity = []\n",
    "total_macro_precision = []\n",
    "total_macro_specificity = []\n",
    "total_macro_F1 = []\n",
    "\n",
    "total_pre_graph = []\n",
    "total_pre_graph1 = []\n",
    "total_pre_graph2 = []\n",
    "total_re_graph = []\n",
    "total_re_graph1 = []\n",
    "total_re_graph2 = []\n",
    "total_thresholds = []\n",
    "total_thresholds1 = []\n",
    "total_thresholds2 = []\n",
    "total_auc_pr = []\n",
    "total_auc_pr1 = []\n",
    "total_auc_pr2 = []\n",
    "    \n",
    "total_fpr = []\n",
    "total_tpr = []\n",
    "total_thresholds_roc = []\n",
    "total_auc_roc = []\n",
    "total_fpr1 = []\n",
    "total_tpr1 = []\n",
    "total_thresholds_roc1 = []\n",
    "total_auc_roc1 = []\n",
    "total_fpr2 = []\n",
    "total_tpr2 = []\n",
    "total_thresholds_roc2 = []\n",
    "total_auc_roc2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    data = Data_load(i+1)\n",
    "    try:\n",
    "        recall_normal = 100*total_recall[i]/total_q[i]\n",
    "        #print(\"Normal_sensitivity\", round(recall_normal,1))\n",
    "        total_normal_sensitivity.append(recall_normal)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        precision_normal = 100*total_precision[i]/total_w[i]\n",
    "        #print(\"Normal_precision\", round(precision_normal,1))\n",
    "        total_normal_precision.append(precision_normal)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        specificity_normal = 100*total_specificity[i]/total_e[i]\n",
    "        #print(\"Normal_specificity\", round(specificity_normal,1))\n",
    "        total_normal_specificity.append(specificity_normal)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        F1_normal = 2*recall_normal*precision_normal/(recall_normal+precision_normal)\n",
    "        #print('Normal_F1-score', round(F1_normal,1))\n",
    "        total_normal_F1.append(F1_normal)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #print(\"-----------------\")\n",
    "    #print(\"test_average_loss\",loss_sum)\n",
    "    try:\n",
    "        recall_mci = 100*total_recall1[i]/total_q1[i]\n",
    "        #print(\"MCI_sensitivity\", round(recall_mci,1))\n",
    "        total_mci_sensitivity.append(recall_mci)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        precision_mci = 100*total_precision1[i]/total_w1[i]\n",
    "        #print(\"MCI_precision\", round(precision_mci,1))\n",
    "        total_mci_precision.append(precision_mci)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        specificity_mci = 100*total_specificity1[i]/total_e1[i]\n",
    "        #print(\"MCI_specificity\", round(specificity_mci,1))\n",
    "        total_mci_specificity.append(specificity_mci)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        F1_mci = 2*recall_mci*precision_mci/(recall_mci+precision_mci)\n",
    "        #print('MCI_F1-score', round(F1_mci,1))\n",
    "        total_mci_F1.append(F1_mci)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #print(\"-----------------\")\n",
    "    #print(\"test_average_loss\",loss_sum)\n",
    "    try:\n",
    "        recall_ad = 100*total_recall2[i]/total_q2[i]\n",
    "        #print(\"AD_sensitivity\", round(recall_ad,1))\n",
    "        total_ad_sensitivity.append(recall_ad)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        precision_ad = 100*total_precision2[i]/total_w2[i]\n",
    "        #print(\"AD_precision\", round(precision_ad,1))\n",
    "        total_ad_precision.append(precision_ad)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        specificity_ad = 100*total_specificity2[i]/total_e2[i]\n",
    "        #print(\"AD_specificity\", round(specificity_ad,1))\n",
    "        total_ad_specificity.append(specificity_ad)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        F1_ad = 2*recall_ad*precision_ad/(recall_ad+precision_ad)\n",
    "        #print('AD_F1-score', round(F1_ad,1))\n",
    "        total_ad_F1.append(F1_ad)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #print(\"-----------------\")\n",
    "    try:\n",
    "        temp_accuracy = 100*total_accuracy_sum[i]/data.test_len\n",
    "        #print(\"Total_Accuracy\", round(temp_accuracy,1))\n",
    "        total_accuracy.append(temp_accuracy)\n",
    "    except:\n",
    "        pass\n",
    "    #print(\"-----------------\")\n",
    "    #print(\"test_average_loss\",loss_sum)\n",
    "    try:\n",
    "        macro_recall = (recall_normal + recall_mci + recall_ad)/3\n",
    "        #print(\"Macro_sensitivity\", round(macro_recall,1))\n",
    "        total_macro_sensitivity.append(macro_recall)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        macro_precision = (precision_normal + precision_mci + precision_ad)/3\n",
    "        #print(\"Macro_precision\", round(macro_precision,1))\n",
    "        total_macro_precision.append(macro_precision)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        macro_specificity = (specificity_normal + specificity_mci + specificity_ad)/3\n",
    "        #print(\"Macro_specificity\", round(macro_specificity,1))\n",
    "        total_macro_specificity.append(macro_specificity)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        macro_F1 = 2*macro_recall*macro_precision/(macro_recall+macro_precision)\n",
    "        #print('Macro_F1-score', round(macro_F1,1))\n",
    "        total_macro_F1.append(macro_F1)\n",
    "    except:\n",
    "        pass\n",
    "    #print(\"-----------------\")\n",
    "    final_y = np.array(total_final_y[i]).astype(int)\n",
    "    final_pred=np.array(total_final_pred[i])\n",
    "    #print(final_y.shape)\n",
    "    pre_graph, re_graph, thresholds = sklearn.metrics.precision_recall_curve(final_y[:,0],final_pred[:,0])\n",
    "    auc_pr = sklearn.metrics.average_precision_score(final_y[:,0],final_pred[:,0])\n",
    "    pre_graph1, re_graph1, thresholds1 = sklearn.metrics.precision_recall_curve(final_y[:,1],final_pred[:,1])\n",
    "    auc_pr1 = sklearn.metrics.average_precision_score(final_y[:,1],final_pred[:,1])\n",
    "    pre_graph2, re_graph2, thresholds2 = sklearn.metrics.precision_recall_curve(final_y[:,2],final_pred[:,2])\n",
    "    auc_pr2 = sklearn.metrics.average_precision_score(final_y[:,2],final_pred[:,2])\n",
    "    #print(type(pre_graph))\n",
    "    total_pre_graph.append(pre_graph)\n",
    "    total_pre_graph1.append(pre_graph1)\n",
    "    total_pre_graph2.append(pre_graph2)\n",
    "    total_re_graph.append(re_graph)\n",
    "    total_re_graph1.append(re_graph1)\n",
    "    total_re_graph2.append(re_graph2)\n",
    "    total_thresholds.append(thresholds)\n",
    "    total_thresholds1.append(thresholds1)\n",
    "    total_thresholds2.append(thresholds2)\n",
    "    total_auc_pr.append(auc_pr)\n",
    "    total_auc_pr1.append(auc_pr1)\n",
    "    total_auc_pr2.append(auc_pr2)\n",
    "    \n",
    "    fpr, tpr, thresholds_roc = sklearn.metrics.roc_curve(final_y[:,0],final_pred[:,0])\n",
    "    auc_roc = sklearn.metrics.roc_auc_score(final_y[:,0],final_pred[:,0])\n",
    "    fpr1, tpr1, thresholds_roc1 = sklearn.metrics.roc_curve(final_y[:,1],final_pred[:,1])\n",
    "    auc_roc1 = sklearn.metrics.roc_auc_score(final_y[:,1],final_pred[:,1])\n",
    "    fpr2, tpr2, thresholds_roc2 = sklearn.metrics.roc_curve(final_y[:,2],final_pred[:,2])\n",
    "    auc_roc2 = sklearn.metrics.roc_auc_score(final_y[:,2],final_pred[:,2])\n",
    "    \n",
    "    total_fpr.append(fpr)\n",
    "    total_tpr.append(tpr)\n",
    "    total_thresholds_roc.append(thresholds_roc)\n",
    "    total_auc_roc.append(auc_roc)\n",
    "    total_fpr1.append(fpr1)\n",
    "    total_tpr1.append(tpr1)\n",
    "    total_thresholds_roc1.append(thresholds_roc1)\n",
    "    total_auc_roc1.append(auc_roc1)\n",
    "    total_fpr2.append(fpr2)\n",
    "    total_tpr2.append(tpr2)\n",
    "    total_thresholds_roc2.append(thresholds_roc2)\n",
    "    total_auc_roc2.append(auc_roc2)\n",
    "    \n",
    "\n",
    "name_list = [\\\n",
    "\"total_accuracy\",\\\n",
    "\"total_normal_sensitivity\",\\\n",
    "\"total_normal_precision\",\\\n",
    "\"total_normal_specificity\",\\\n",
    "\"total_normal_F1\",\\\n",
    "\"total_mci_sensitivity\",\\\n",
    "\"total_mci_precision\",\\\n",
    "\"total_mci_specificity\",\\\n",
    "\"total_mci_F1\",\\\n",
    "\"total_ad_sensitivity\",\\\n",
    "\"total_ad_precision\",\\\n",
    "\"total_ad_specificity\",\\\n",
    "\"total_ad_F1\",\\\n",
    "\"total_macro_sensitivity\",\\\n",
    "\"total_macro_precision\",\\\n",
    "\"total_macro_specificity\",\\\n",
    "\"total_macro_F1\"]\n",
    "\n",
    "list_list = [\\\n",
    "total_accuracy,\\\n",
    "total_normal_sensitivity,\\\n",
    "total_normal_precision,\\\n",
    "total_normal_specificity,\\\n",
    "total_normal_F1,\\\n",
    "total_mci_sensitivity,\\\n",
    "total_mci_precision,\\\n",
    "total_mci_specificity,\\\n",
    "total_mci_F1,\\\n",
    "total_ad_sensitivity,\\\n",
    "total_ad_precision,\\\n",
    "total_ad_specificity,\\\n",
    "total_ad_F1,\\\n",
    "total_macro_sensitivity,\\\n",
    "total_macro_precision,\\\n",
    "total_macro_specificity,\\\n",
    "total_macro_F1]\n",
    "\n",
    "for num, i in enumerate(list_list):\n",
    "    print(name_list[num],round(np.mean(i),1), \"------------\", round(np.std(i,ddof=1),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b87e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inter_fpr = np.insert(np.linspace(0,1,num=2000),0,0)\n",
    "inter_tpr = []\n",
    "inter_tpr1 = []\n",
    "inter_tpr2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    a = np.linspace(0,1,num=2000)\n",
    "    b = np.insert(np.interp(a,total_fpr[i],total_tpr[i]),0,0)\n",
    "    inter_tpr.append(b)\n",
    "\n",
    "    a = np.linspace(0,1,num=2000)\n",
    "    b = np.insert(np.interp(a,total_fpr1[i],total_tpr1[i]),0,0)\n",
    "    inter_tpr1.append(b)\n",
    "    \n",
    "    a = np.linspace(0,1,num=2000)\n",
    "    b = np.insert(np.interp(a,total_fpr2[i],total_tpr2[i]),0,0)\n",
    "    inter_tpr2.append(b)\n",
    "\n",
    "inter_con_up_tpr = []\n",
    "inter_con_up_tpr1 = []\n",
    "inter_con_up_tpr2 = []\n",
    "inter_con_down_tpr = []\n",
    "inter_con_down_tpr1 = []\n",
    "inter_con_down_tpr2 = []\n",
    "inter_aver = []\n",
    "inter_aver1 = []\n",
    "inter_aver2 = []\n",
    "\n",
    "for i in range(2001):\n",
    "    temp_temp_list = list()\n",
    "    for j in range(5):\n",
    "        temp_temp_list.append(inter_tpr[j][i])\n",
    "    temp_aver = np.average(temp_temp_list)\n",
    "    temp_std = np.std(temp_temp_list,ddof=1) ##\n",
    "    interest_temp = 2.776*temp_std/np.sqrt(5)\n",
    "    inter_con_up_tpr.append(temp_aver+interest_temp)\n",
    "    inter_con_down_tpr.append(temp_aver-interest_temp)\n",
    "    inter_aver.append(temp_aver)\n",
    "    \n",
    "    temp_temp_list = list()\n",
    "    for j in range(5):\n",
    "        temp_temp_list.append(inter_tpr1[j][i])\n",
    "    #print(temp_temp_list)\n",
    "    temp_aver = np.average(temp_temp_list)\n",
    "    temp_std = np.std(temp_temp_list,ddof=1)\n",
    "    interest_temp = 2.776*temp_std/np.sqrt(5)\n",
    "    inter_con_up_tpr1.append(temp_aver+interest_temp)\n",
    "    inter_con_down_tpr1.append(temp_aver-interest_temp)\n",
    "    inter_aver1.append(temp_aver)\n",
    "    \n",
    "    temp_temp_list = list()\n",
    "    for j in range(5):\n",
    "        temp_temp_list.append(inter_tpr2[j][i])\n",
    "    #print(temp_temp_list)\n",
    "    temp_aver = np.average(temp_temp_list)\n",
    "    temp_std = np.std(temp_temp_list,ddof=1)\n",
    "    interest_temp = 2.776*temp_std/np.sqrt(5)\n",
    "    inter_con_up_tpr2.append(temp_aver+interest_temp)\n",
    "    inter_con_down_tpr2.append(temp_aver-interest_temp)\n",
    "    inter_aver2.append(temp_aver)\n",
    "\n",
    "random_roc_x = np.array([0,1])\n",
    "random_roc_y = np.array([0,1])\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax1 = fig.add_subplot()\n",
    "auc_average = np.average(total_auc_roc)\n",
    "auc_std = np.std(total_auc_roc,ddof=1)\n",
    "auc_average1 = np.average(total_auc_roc1)\n",
    "auc_std1 = np.std(total_auc_roc1,ddof=1)\n",
    "auc_average2 = np.average(total_auc_roc2)\n",
    "auc_std2 = np.std(total_auc_roc2,ddof=1)\n",
    "\n",
    "line1=ax1.plot(inter_fpr, inter_aver, label='Normal, AUC: '+str(round(auc_average,3))+'±'+str(round(auc_std,3)), color='red')\n",
    "line2=ax1.plot(inter_fpr, inter_aver1, label='MCI, AUC: '+str(round(auc_average1,3))+'±'+str(round(auc_std1,3)), color='green')\n",
    "line3=ax1.plot(inter_fpr, inter_aver2, label='Dementia, AUC: '+str(round(auc_average2,3))+'±'+str(round(auc_std2,3)), color='blue')\n",
    "line4=ax1.fill_between(inter_fpr,inter_con_up_tpr,inter_con_down_tpr,alpha=0.3, color='red')\n",
    "line5=ax1.fill_between(inter_fpr,inter_con_up_tpr1,inter_con_down_tpr1,alpha=0.3, color='green')\n",
    "line6=ax1.fill_between(inter_fpr,inter_con_up_tpr2,inter_con_down_tpr2,alpha=0.3, color='blue')\n",
    "line7=ax1.plot(random_roc_x,random_roc_y, label='Baseline, AUC: '+str(0.5),linestyle = '--', color='black')\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "lines = line1 + line2 + line3 + line7\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc45a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inter_fpr = np.linspace(0,1,num=2000)\n",
    "inter_pre = []\n",
    "inter_pre1 = []\n",
    "inter_pre2 = []\n",
    "\n",
    "for i in range(5):\n",
    "    a = np.linspace(0,1,num=2000)\n",
    "    b = np.interp(a,np.flip(total_re_graph[i]),np.flip(total_pre_graph[i]))\n",
    "    inter_pre.append(b)\n",
    "\n",
    "    a = np.linspace(0,1,num=2000)\n",
    "    b = np.interp(a,np.flip(total_re_graph1[i]),np.flip(total_pre_graph1[i]))\n",
    "    inter_pre1.append(b)\n",
    "    \n",
    "    a = np.linspace(0,1,num=2000)\n",
    "    b = np.interp(a,np.flip(total_re_graph2[i]),np.flip(total_pre_graph2[i]))\n",
    "    inter_pre2.append(b)\n",
    "\n",
    "inter_con_up_pre = []\n",
    "inter_con_up_pre1 = []\n",
    "inter_con_up_pre2 = []\n",
    "inter_con_down_pre = []\n",
    "inter_con_down_pre1 = []\n",
    "inter_con_down_pre2 = []\n",
    "inter_aver_pre = []\n",
    "inter_aver1_pre = []\n",
    "inter_aver2_pre = []\n",
    "\n",
    "for i in range(2000):\n",
    "    temp_temp_list = list()\n",
    "    for j in range(5):\n",
    "        temp_temp_list.append(inter_pre[j][i])\n",
    "    #print(temp_temp_list)\n",
    "    temp_aver = np.average(temp_temp_list)\n",
    "    temp_std = np.std(temp_temp_list,ddof=1)\n",
    "    interest_temp = 2.776*temp_std/np.sqrt(5)\n",
    "    inter_con_up_pre.append(temp_aver+interest_temp)\n",
    "    inter_con_down_pre.append(temp_aver-interest_temp)\n",
    "    inter_aver_pre.append(temp_aver)\n",
    "    \n",
    "    temp_temp_list = list()\n",
    "    for j in range(5):\n",
    "        temp_temp_list.append(inter_pre1[j][i])\n",
    "    #print(temp_temp_list)\n",
    "    temp_aver = np.average(temp_temp_list)\n",
    "    temp_std = np.std(temp_temp_list,ddof=1)\n",
    "    interest_temp = 2.776*temp_std/np.sqrt(5)\n",
    "    inter_con_up_pre1.append(temp_aver+interest_temp)\n",
    "    inter_con_down_pre1.append(temp_aver-interest_temp)\n",
    "    inter_aver1_pre.append(temp_aver)\n",
    "    \n",
    "    temp_temp_list = list()\n",
    "    for j in range(5):\n",
    "        temp_temp_list.append(inter_pre2[j][i])\n",
    "    #print(temp_temp_list)\n",
    "    temp_aver = np.average(temp_temp_list)\n",
    "    temp_std = np.std(temp_temp_list,ddof=1)\n",
    "    interest_temp = 2.776*temp_std/np.sqrt(5)\n",
    "    inter_con_up_pre2.append(temp_aver+interest_temp)\n",
    "    inter_con_down_pre2.append(temp_aver-interest_temp)\n",
    "    inter_aver2_pre.append(temp_aver)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax1 = fig.add_subplot()\n",
    "auc_average = np.average(total_auc_pr)\n",
    "auc_std = np.std(total_auc_pr,ddof=1)\n",
    "auc_average1 = np.average(total_auc_pr1)\n",
    "auc_std1 = np.std(total_auc_pr1,ddof=1)\n",
    "auc_average2 = np.average(total_auc_pr2)\n",
    "auc_std2 = np.std(total_auc_pr2,ddof=1)\n",
    "line1=ax1.plot(inter_fpr, inter_aver_pre, label='Normal, AP: '+str(round(auc_average,3))+'±'+str(round(auc_std,3)), color='red')\n",
    "line2=ax1.plot(inter_fpr, inter_aver1_pre, label='MCI, AP: '+str(round(auc_average1,3))+'±'+str(round(auc_std1,3)), color='green')\n",
    "line3=ax1.plot(inter_fpr, inter_aver2_pre, label='Dementia, AP: '+str(round(auc_average2,3))+'±'+str(round(auc_std2,3)), color='blue')\n",
    "line4=ax1.fill_between(inter_fpr,inter_con_up_pre,inter_con_down_pre,alpha=0.3, color='red')\n",
    "line5=ax1.fill_between(inter_fpr,inter_con_up_pre1,inter_con_down_pre1,alpha=0.3, color='green')\n",
    "line6=ax1.fill_between(inter_fpr,inter_con_up_pre2,inter_con_down_pre2,alpha=0.3, color='blue')\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "lines = line1 + line2 + line3\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='lower center')\n",
    "plt.ylim(0,1.0)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

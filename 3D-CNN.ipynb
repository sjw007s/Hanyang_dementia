{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6293af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from functools import partial\n",
    "from typing import Any, Callable, List, Optional, Type, Union\n",
    "import os\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import random\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import nn\n",
    "import sklearn.metrics\n",
    "import matplotlib\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_name = 'F' #E\n",
    "if device_name == 'F':\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f777f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size=5\n",
    "\n",
    "class Data_load:\n",
    "    def __init__(self,num):\n",
    "        self.len_=0\n",
    "        self.x_data_name=[]\n",
    "        self.x_data_test_name=[]\n",
    "        self.normal_size=0\n",
    "        self.mci_size=0\n",
    "        self.ad_size=0\n",
    "        self.test_len=0\n",
    "        list_disease = ['Normal', 'MCI', 'AD']\n",
    "        for i in range(1,6,1):\n",
    "            for label_target, j in enumerate(list_disease):\n",
    "                part_data_name=[]\n",
    "                path = device_name+\":/k-fold validation/\"+str(i)+\"/\"+str(j)+\"/\"\n",
    "                dir_list = os.listdir(path)\n",
    "                len_dir=len(dir_list)\n",
    "                for k in range(len_dir):\n",
    "                    part_data_name.append([path+dir_list[k], label_target])\n",
    "                if num != i:\n",
    "                    self.x_data_name.append(part_data_name)\n",
    "                else:\n",
    "                    self.x_data_test_name.append(part_data_name)\n",
    "                    if label_target == 0:\n",
    "                        self.normal_size = len_dir\n",
    "                    elif label_target == 1:\n",
    "                        self.mci_size = len_dir\n",
    "                    else:\n",
    "                        self.ad_size = len_dir\n",
    "                    self.test_len+=len_dir\n",
    "                        \n",
    "        \n",
    "        self.final_data_name=[]\n",
    "        self.final_data_test_name=[]\n",
    "        for i in range(len(self.x_data_name)):\n",
    "            for j in range(len(self.x_data_name[i])):\n",
    "                self.final_data_name.append(self.x_data_name[i][j])\n",
    "        for i in range(len(self.x_data_test_name)):\n",
    "            for j in range(len(self.x_data_test_name[i])):\n",
    "                self.final_data_test_name.append(self.x_data_test_name[i][j])\n",
    "        \n",
    "        random.shuffle(self.final_data_name)\n",
    "        \n",
    "    def out(self):\n",
    "        return self.final_data_name, self.final_data_test_name\n",
    "    \n",
    "    def random(self):\n",
    "        random.shuffle(self.final_data_name)\n",
    "        return self.final_data_name\n",
    "\n",
    "def training(data, batch_size):\n",
    "    batch_total = len(data)//batch_size\n",
    "    batch_na = len(data)%batch_size\n",
    "    for i in range(batch_total+1):\n",
    "        x_data=[]\n",
    "        y_data=[]\n",
    "        extra = []\n",
    "        extra_final = []\n",
    "        if i == batch_total:\n",
    "            if batch_na == 0:\n",
    "                break\n",
    "            else:\n",
    "                temp_data = data[i*batch_size:] \n",
    "        else:\n",
    "            temp_data = data[i*batch_size:(i+1)*batch_size]\n",
    "        for j in range(len(temp_data)):\n",
    "            img = nib.load(temp_data[j][0]+'/1/final/1_t1_final.mnc').get_fdata() \n",
    "            img = 255*img/img.max() \n",
    "\n",
    "            x_data.append(img)      \n",
    "            \n",
    "            if temp_data[j][1] == 0:  \n",
    "                y_data.append([1,0,0])\n",
    "            elif temp_data[j][1] == 1:\n",
    "                y_data.append([0,1,0]) \n",
    "            elif temp_data[j][1] == 2: \n",
    "                y_data.append([0,0,1])  \n",
    "    \n",
    "\n",
    "        x_data = torch.from_numpy(np.array(x_data)[:,np.newaxis,:,:,:]).type(torch.FloatTensor).to(\"cuda\")\n",
    "        y_data = torch.from_numpy(np.array(y_data)).type(torch.FloatTensor).to(\"cuda\")\n",
    "\n",
    "        yield (x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6d033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Conv3d(1,64,5,stride=2)\n",
    "        self.layer_2 = nn.MaxPool3d(3)\n",
    "        self.layer_3 = nn.Conv3d(64,128,3,stride=2)\n",
    "        self.layer_4 = nn.MaxPool3d(3)\n",
    "        self.layer_5 = nn.Conv3d(128,256,3,stride=1)\n",
    "        self.layer_6 = nn.Linear(3072,3)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lrelu(self.layer_1(x))\n",
    "        x = self.layer_2(x)\n",
    "        x = self.lrelu(self.layer_3(x))\n",
    "        x = self.layer_4(x)\n",
    "        x = self.lrelu(self.layer_5(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer_6(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abccdb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nSamples = [1,2,3]\n",
    "weights = torch.tensor(nSamples).to(device)\n",
    "for tt in range(1,4,1):\n",
    "    model = CNN().to(\"cuda\")\n",
    "    loss_fn = nn.CrossEntropyLoss(weight= weights, reduction='sum')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    data = Data_load(tt)\n",
    "    for t in range(epochs):\n",
    "        X_training = data.random()\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(training(X_training,batch_size)):\n",
    "            pred = model(X)\n",
    "            batch_loss_result = loss_fn(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss_result.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    torch.save(model,\"3D_CNN_\"+str(tt)+\".pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08eaf6cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\naccuracy_list=list()\\nroc_normal_list = list()\\nroc_mci_list = list()\\nroc_ad_list = list()\\ntraining_list=list()\\ntest_list=list()\\nnSamples = [1,2,3]\\nweights = torch.tensor(nSamples).to(device)\\nprint(weights)\\nfor tt in range(1,4,1):\\n    model = CNN().to(device)\\n    loss_fn = nn.CrossEntropyLoss(weight= weights, reduction=\\'sum\\')\\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\\n    data = Data_load(tt)\\n    _,X_test = data.out()\\n    accuracy = 0\\n    \\n    for t in range(epochs):\\n        print(f\"Epoch {t}\\n-------------------------------\")\\n        loss_sum=0\\n        X_training = data.random()\\n        model.train()\\n        for batch, (X, y) in enumerate(training(X_training,batch_size)):\\n            pred = model(X)\\n            batch_loss_result = loss_fn(pred, y)\\n            optimizer.zero_grad()\\n            batch_loss_result.backward()\\n            optimizer.step()\\n            loss_sum+=batch_loss_result\\n       \\n        loss_sum=loss_sum/(batch+1)\\n        training_list.append(loss_sum)\\n        print(\"train_average_loss\",loss_sum)\\n        A=np.zeros((3,3))\\n        model.eval()\\n        with torch.no_grad():\\n            loss_sum=0\\n            final_pred=[]\\n            final_y=[]\\n            \\n            accuracy_sum=0\\n            precision = 0\\n            recall = 0\\n            specificity=0\\n            q = 0\\n            w = 0\\n            e = 0\\n            \\n            precision1 = 0\\n            recall1 = 0\\n            specificity1=0\\n            q1 = 0\\n            w1 = 0\\n            e1 = 0\\n            \\n            precision2 = 0\\n            recall2 = 0\\n            specificity2=0\\n            q2 = 0\\n            w2 = 0\\n            e2 = 0\\n            for batch, (X, y) in enumerate(training(X_test,batch_size)):\\n                pred = model(X)\\n                pred_softmax = F.softmax(pred,dim=1)\\n                #print(pred,pred_softmax,y)\\n                for i in range(y.shape[0]):\\n                    final_pred.append(pred_softmax[i].to(\\'cpu\\').numpy())\\n                    final_y.append(y[i].to(\\'cpu\\').numpy())\\n                batch_loss_result = loss_fn(pred, y)\\n                loss_sum+=batch_loss_result\\n                \\n                for i in range(y.shape[0]):\\n                    if torch.argmax(y[i], dim=0) == 0:\\n                        if torch.argmax(pred[i], dim=0) == 0:\\n                            accuracy_sum+= 1\\n                    elif torch.argmax(y[i], dim=0) == 1:\\n                        if torch.argmax(pred[i], dim=0) == 1:\\n                            accuracy_sum+= 1\\n                    elif torch.argmax(y[i], dim=0) == 2:\\n                        if torch.argmax(pred[i], dim=0) == 2:\\n                            accuracy_sum+= 1\\n                    \\n                    if torch.argmax(y[i], dim=0) == 0:\\n                        q+=1\\n                        if torch.argmax(pred[i], dim=0) == 0:\\n                            recall += 1\\n                    if torch.argmax(pred[i], dim=0) == 0:\\n                        w+=1\\n                        if torch.argmax(y[i], dim=0) == 0:\\n                            precision +=1\\n                    if torch.argmax(y[i], dim=0) != 0:\\n                        e+=1\\n                        if torch.argmax(pred[i], dim=0) != 0:\\n                            specificity +=1\\n                    \\n                    if torch.argmax(y[i], dim=0) == 1:\\n                        q1+=1\\n                        if torch.argmax(pred[i], dim=0) == 1:\\n                            recall1 += 1\\n                    if torch.argmax(pred[i], dim=0) == 1:\\n                        w1+=1\\n                        if torch.argmax(y[i], dim=0) == 1:\\n                            precision1 +=1\\n                    if torch.argmax(y[i], dim=0) != 1:\\n                        e1+=1\\n                        if torch.argmax(pred[i], dim=0) != 1:\\n                            specificity1 +=1\\n                    \\n                    if torch.argmax(y[i], dim=0) == 2:\\n                        q2+=1\\n                        if torch.argmax(pred[i], dim=0) == 2:\\n                            recall2 += 1\\n                    if torch.argmax(pred[i], dim=0) == 2:\\n                        w2+=1\\n                        if torch.argmax(y[i], dim=0) == 2:\\n                            precision2 +=1\\n                    if torch.argmax(y[i], dim=0) != 2:\\n                        e2+=1\\n                        if torch.argmax(pred[i], dim=0) != 2:\\n                            specificity2 +=1\\n                \\n                pred_index = torch.argmax(pred,dim=1)\\n                y_index = torch.argmax(y,dim=1)\\n                for i in range(pred.shape[0]):\\n                    A[pred_index[i],y_index[i]]+=1\\n            final_y = np.array(final_y).astype(int)\\n            final_pred=np.array(final_pred)\\n            \\n            pre_graph, re_graph, thresholds = sklearn.metrics.precision_recall_curve(final_y[:,0],final_pred[:,0])\\n            auc_pr = sklearn.metrics.average_precision_score(final_y[:,0],final_pred[:,0])\\n            pre_graph1, re_graph1, thresholds1 = sklearn.metrics.precision_recall_curve(final_y[:,1],final_pred[:,1])\\n            auc_pr1 = sklearn.metrics.average_precision_score(final_y[:,1],final_pred[:,1])\\n            pre_graph2, re_graph2, thresholds2 = sklearn.metrics.precision_recall_curve(final_y[:,2],final_pred[:,2])\\n            auc_pr2 = sklearn.metrics.average_precision_score(final_y[:,2],final_pred[:,2])\\n\\n            fig = plt.figure(figsize=(6, 6))\\n            ax1 = fig.add_subplot()\\n            base_x = np.array([0,1])\\n            nor_base_y = np.array([round(data.normal_size/data.test_len,3),round(data.normal_size/data.test_len,3)])\\n            mci_base_y = np.array([round(data.mci_size/data.test_len,3),round(data.mci_size/data.test_len,3)])\\n            ad_base_y = np.array([round(data.ad_size/data.test_len,3),round(data.ad_size/data.test_len,3)])\\n            line1=ax1.plot(re_graph, pre_graph, label=\\'Normal vs Others, AUC: \\'+str(round(auc_pr,3)), color=\\'red\\')\\n            line2=ax1.plot(re_graph1, pre_graph1, label=\\'MCI vs Others, AUC: \\'+str(round(auc_pr1,3)), color=\\'blue\\')\\n            line3=ax1.plot(re_graph2, pre_graph2, label=\\'AD vs Others, AUC: \\'+str(round(auc_pr2,3)), color=\\'green\\')\\n            line4=ax1.plot(base_x,nor_base_y,linestyle=\\'--\\', color=\\'red\\', label=\\'Normal baseline, AUC: \\'+str(round(data.normal_size/data.test_len,3)))\\n            line5=ax1.plot(base_x,mci_base_y,linestyle=\\'--\\', color=\\'blue\\', label=\\'MCI baseline, AUC: \\'+str(round(data.mci_size/data.test_len,3)))\\n            line6=ax1.plot(base_x,ad_base_y,linestyle=\\'--\\', color=\\'green\\', label=\\'AD baseline, AUC: \\'+str(round(data.ad_size/data.test_len,3)))\\n            #ax2.set_ylabel(\\'Accuracy\\')\\n            ax1.set_xlabel(\\'Recall\\')\\n            ax1.set_ylabel(\\'Precision\\')\\n            lines = line1 + line2 + line3 + line4 + line5 + line6\\n            labels = [l.get_label() for l in lines]\\n            ax1.legend(lines, labels, loc=\\'upper left\\', bbox_to_anchor=(1, 1))\\n            plt.grid(True)\\n            print(\"Normal AP: \",round(auc_pr,3))\\n            print(\"MCI AP: \",round(auc_pr1,3))\\n            print(\"AD AP: \",round(auc_pr2,3))\\n            plt.show()\\n            plt.close()\\n            \\n            random_roc_x = np.array([0,1])\\n            random_roc_y = np.array([0,1])\\n            fpr, tpr, thresholds_roc = sklearn.metrics.roc_curve(final_y[:,0],final_pred[:,0])\\n            auc_roc = sklearn.metrics.roc_auc_score(final_y[:,0],final_pred[:,0])\\n            fpr1, tpr1, thresholds_roc1 = sklearn.metrics.roc_curve(final_y[:,1],final_pred[:,1])\\n            auc_roc1 = sklearn.metrics.roc_auc_score(final_y[:,1],final_pred[:,1])\\n            fpr2, tpr2, thresholds_roc2 = sklearn.metrics.roc_curve(final_y[:,2],final_pred[:,2])\\n            auc_roc2 = sklearn.metrics.roc_auc_score(final_y[:,2],final_pred[:,2])\\n\\n            fig = plt.figure(figsize=(6, 6))\\n            ax1 = fig.add_subplot()\\n            line1=ax1.plot(fpr, tpr, label=\\'Normal vs Others, AUC: \\'+str(round(auc_roc,3)), color=\\'red\\')\\n            line2=ax1.plot(fpr1, tpr1, label=\\'MCI vs Others, AUC: \\'+str(round(auc_roc1,3)), color=\\'blue\\')\\n            line3=ax1.plot(fpr2, tpr2, label=\\'AD vs Others, AUC: \\'+str(round(auc_roc2,3)), color=\\'green\\')\\n            line4=ax1.plot(random_roc_x,random_roc_y, label=\\'Baseline, AUC: \\'+str(0.5),linestyle = \\'--\\', color=\\'black\\')\\n            #ax2.set_ylabel(\\'Accuracy\\')\\n            ax1.set_xlabel(\\'False Positive Rate\\')\\n            ax1.set_ylabel(\\'True Positive Rate\\')\\n            lines = line1 + line2 + line3 + line4\\n            labels = [l.get_label() for l in lines]\\n            ax1.legend(lines, labels, loc=\\'upper left\\', bbox_to_anchor=(1, 1))\\n            plt.grid(True)\\n            print(\"Normal AUC: \",round(auc_roc,3))\\n            print(\"MCI AUC: \",round(auc_roc1,3))\\n            print(\"AD AUC: \",round(auc_roc2,3))\\n            plt.show()\\n            plt.close()\\n            print(\"-----------------\")\\n         \\n            #print(\"test_average_loss\",loss_sum)\\n            try:\\n                recall_normal = 100*recall/q\\n                print(\"Normal_sensitivity\", round(recall_normal,1))\\n            except:\\n                pass\\n            try:\\n                precision_normal = 100*precision/w\\n                print(\"Normal_precision\", round(precision_normal,1))\\n            except:\\n                pass\\n            try:\\n                specificity_normal = 100*specificity/e\\n                print(\"Normal_specificity\", round(specificity_normal,1))\\n            except:\\n                pass\\n            try:\\n                F1_normal = 2*recall_normal*precision_normal/(recall_normal+precision_normal)\\n                print(\\'Normal_F1-score\\', round(F1_normal,1))\\n            except:\\n                pass\\n            \\n            print(\"-----------------\")\\n            #print(\"test_average_loss\",loss_sum)\\n            try:\\n                recall_mci = 100*recall1/q1\\n                print(\"MCI_sensitivity\", round(recall_mci,1))\\n            except:\\n                pass\\n            try:\\n                precision_mci = 100*precision1/w1\\n                print(\"MCI_precision\", round(precision_mci,1))\\n            except:\\n                pass\\n            try:\\n                specificity_mci = 100*specificity1/e1\\n                print(\"MCI_specificity\", round(specificity_mci,1))\\n            except:\\n                pass\\n            try:\\n                F1_mci = 2*recall_mci*precision_mci/(recall_mci+precision_mci)\\n                print(\\'MCI_F1-score\\', round(F1_mci,1))\\n            except:\\n                pass\\n            \\n            print(\"-----------------\")\\n            #print(\"test_average_loss\",loss_sum)\\n            try:\\n                recall_ad = 100*recall2/q2\\n                print(\"AD_sensitivity\", round(recall_ad,1))\\n            except:\\n                pass\\n            try:\\n                precision_ad = 100*precision2/w2\\n                print(\"AD_precision\", round(precision_ad,1))\\n            except:\\n                pass\\n            try:\\n                specificity_ad = 100*specificity2/e2\\n                print(\"AD_specificity\", round(specificity_ad,1))\\n            except:\\n                pass\\n            try:\\n                F1_ad = 2*recall_ad*precision_ad/(recall_ad+precision_ad)\\n                print(\\'AD_F1-score\\', round(F1_ad,1))\\n            except:\\n                pass\\n            \\n            print(\"-----------------\")\\n            try:\\n                temp_accuracy = 100*accuracy_sum/len(X_test)\\n                print(\"Total_Accuracy\", round(temp_accuracy,1))\\n            except:\\n                pass\\n            print(\"-----------------\")\\n            #print(\"test_average_loss\",loss_sum)\\n            try:\\n                macro_recall = (recall_normal + recall_mci + recall_ad)/3\\n                print(\"Macro_sensitivity\", round(macro_recall,1))\\n            except:\\n                pass\\n            try:\\n                macro_precision = (precision_normal + precision_mci + precision_ad)/3\\n                print(\"Macro_precision\", round(macro_precision,1))\\n            except:\\n                pass\\n            try:\\n                macro_specificity = (specificity_normal + specificity_mci + specificity_ad)/3\\n                print(\"Macro_specificity\", round(macro_specificity,1))\\n            except:\\n                pass\\n            try:\\n                macro_F1 = 2*macro_recall*macro_precision/(macro_recall+macro_precision)\\n                print(\\'Macro_F1-score\\', round(macro_F1,1))\\n            except:\\n                pass\\n            print(\"-----------------\")\\n            print(A)\\n            \\n            loss_sum=loss_sum/(batch+1)\\n            accuracy_list.append(temp_accuracy/100)\\n            roc_normal_list.append(round(auc_roc,3))\\n            roc_mci_list.append(round(auc_roc1,3))\\n            roc_ad_list.append(round(auc_roc2,3))\\n            test_list.append(loss_sum)\\n            print(\"test_average_loss\",loss_sum)\\n        \\n        if temp_accuracy > accuracy:\\n            accuracy = temp_accuracy\\n            #torch.save(model,\"Resnet_\"+str(accuracy)+\".pt\")\\ntime_steps = list(range(1, len(training_list) + 1))\\n\\n# Plot the learning curve\\nfor i in range(len(training_list)):\\n    training_list[i] = training_list[i].cpu().detach().numpy()\\n    test_list[i] = test_list[i].cpu().detach().numpy()\\n    \\nfig = plt.figure(figsize=(8, 6))\\nax1 = fig.add_subplot()\\nline1=ax1.plot(time_steps, training_list, label=\\'Training Loss\\',color=\\'red\\')\\nline2=ax1.plot(time_steps, test_list, label=\\'Test Loss\\',color=\\'blue\\')\\nax2 = plt.twinx()\\nline3=ax2.plot(time_steps, roc_normal_list, label=\\'AUC_Normal\\',color=\\'green\\')\\nline4=ax2.plot(time_steps, roc_mci_list, label=\\'AUC_MCI\\',color=\\'orange\\')\\nline5=ax2.plot(time_steps, roc_ad_list, label=\\'AUC_AD\\',color=\\'gray\\')\\nline6=ax2.plot(time_steps, accuracy_list, label=\\'Accuracy\\',color=\\'brown\\')\\n#ax2.set_ylabel(\\'Accuracy\\')\\nax1.set_xlabel(\\'Time\\')\\nax1.set_ylabel(\\'Loss\\')\\n\\nlines = line1 + line2 + line3 + line4 + line5 + line6\\nlabels = [l.get_label() for l in lines]\\nax1.legend(lines, labels, loc=\\'upper left\\', bbox_to_anchor=(1.1, 1))\\nplt.grid(True)\\nplt.show()\\nprint(\"Done!\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "nSamples = [1,2,3]\n",
    "weights = torch.tensor(nSamples).to(device)\n",
    "print(weights)\n",
    "for tt in range(1,4,1):\n",
    "    accuracy_list=list()\n",
    "    roc_normal_list = list()\n",
    "    roc_mci_list = list()\n",
    "    roc_ad_list = list()\n",
    "    training_list=list()\n",
    "    test_list=list()\n",
    "    model = CNN().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight= weights, reduction='sum')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    data = Data_load(tt)\n",
    "    _,X_test = data.out()\n",
    "    accuracy = 0\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        loss_sum=0\n",
    "        X_training = data.random()\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(training(X_training,batch_size)):\n",
    "            pred = model(X)\n",
    "            batch_loss_result = loss_fn(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss_result.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum+=batch_loss_result\n",
    "       \n",
    "        loss_sum=loss_sum/(batch+1)\n",
    "        training_list.append(loss_sum)\n",
    "        print(\"train_average_loss\",loss_sum)\n",
    "        A=np.zeros((3,3))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_sum=0\n",
    "            final_pred=[]\n",
    "            final_y=[]\n",
    "            \n",
    "            accuracy_sum=0\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            specificity=0\n",
    "            q = 0\n",
    "            w = 0\n",
    "            e = 0\n",
    "            \n",
    "            precision1 = 0\n",
    "            recall1 = 0\n",
    "            specificity1=0\n",
    "            q1 = 0\n",
    "            w1 = 0\n",
    "            e1 = 0\n",
    "            \n",
    "            precision2 = 0\n",
    "            recall2 = 0\n",
    "            specificity2=0\n",
    "            q2 = 0\n",
    "            w2 = 0\n",
    "            e2 = 0\n",
    "            for batch, (X, y) in enumerate(training(X_test,batch_size)):\n",
    "                pred = model(X)\n",
    "                pred_softmax = F.softmax(pred,dim=1)\n",
    "                #print(pred,pred_softmax,y)\n",
    "                for i in range(y.shape[0]):\n",
    "                    final_pred.append(pred_softmax[i].to('cpu').numpy())\n",
    "                    final_y.append(y[i].to('cpu').numpy())\n",
    "                batch_loss_result = loss_fn(pred, y)\n",
    "                loss_sum+=batch_loss_result\n",
    "                \n",
    "                for i in range(y.shape[0]):\n",
    "                    if torch.argmax(y[i], dim=0) == 0:\n",
    "                        if torch.argmax(pred[i], dim=0) == 0:\n",
    "                            accuracy_sum+= 1\n",
    "                    elif torch.argmax(y[i], dim=0) == 1:\n",
    "                        if torch.argmax(pred[i], dim=0) == 1:\n",
    "                            accuracy_sum+= 1\n",
    "                    elif torch.argmax(y[i], dim=0) == 2:\n",
    "                        if torch.argmax(pred[i], dim=0) == 2:\n",
    "                            accuracy_sum+= 1\n",
    "                    \n",
    "                    if torch.argmax(y[i], dim=0) == 0:\n",
    "                        q+=1\n",
    "                        if torch.argmax(pred[i], dim=0) == 0:\n",
    "                            recall += 1\n",
    "                    if torch.argmax(pred[i], dim=0) == 0:\n",
    "                        w+=1\n",
    "                        if torch.argmax(y[i], dim=0) == 0:\n",
    "                            precision +=1\n",
    "                    if torch.argmax(y[i], dim=0) != 0:\n",
    "                        e+=1\n",
    "                        if torch.argmax(pred[i], dim=0) != 0:\n",
    "                            specificity +=1\n",
    "                    \n",
    "                    if torch.argmax(y[i], dim=0) == 1:\n",
    "                        q1+=1\n",
    "                        if torch.argmax(pred[i], dim=0) == 1:\n",
    "                            recall1 += 1\n",
    "                    if torch.argmax(pred[i], dim=0) == 1:\n",
    "                        w1+=1\n",
    "                        if torch.argmax(y[i], dim=0) == 1:\n",
    "                            precision1 +=1\n",
    "                    if torch.argmax(y[i], dim=0) != 1:\n",
    "                        e1+=1\n",
    "                        if torch.argmax(pred[i], dim=0) != 1:\n",
    "                            specificity1 +=1\n",
    "                    \n",
    "                    if torch.argmax(y[i], dim=0) == 2:\n",
    "                        q2+=1\n",
    "                        if torch.argmax(pred[i], dim=0) == 2:\n",
    "                            recall2 += 1\n",
    "                    if torch.argmax(pred[i], dim=0) == 2:\n",
    "                        w2+=1\n",
    "                        if torch.argmax(y[i], dim=0) == 2:\n",
    "                            precision2 +=1\n",
    "                    if torch.argmax(y[i], dim=0) != 2:\n",
    "                        e2+=1\n",
    "                        if torch.argmax(pred[i], dim=0) != 2:\n",
    "                            specificity2 +=1\n",
    "                \n",
    "                pred_index = torch.argmax(pred,dim=1)\n",
    "                y_index = torch.argmax(y,dim=1)\n",
    "                for i in range(pred.shape[0]):\n",
    "                    A[pred_index[i],y_index[i]]+=1\n",
    "            final_y = np.array(final_y).astype(int)\n",
    "            final_pred=np.array(final_pred)\n",
    "            \n",
    "            pre_graph, re_graph, thresholds = sklearn.metrics.precision_recall_curve(final_y[:,0],final_pred[:,0])\n",
    "            auc_pr = sklearn.metrics.average_precision_score(final_y[:,0],final_pred[:,0])\n",
    "            pre_graph1, re_graph1, thresholds1 = sklearn.metrics.precision_recall_curve(final_y[:,1],final_pred[:,1])\n",
    "            auc_pr1 = sklearn.metrics.average_precision_score(final_y[:,1],final_pred[:,1])\n",
    "            pre_graph2, re_graph2, thresholds2 = sklearn.metrics.precision_recall_curve(final_y[:,2],final_pred[:,2])\n",
    "            auc_pr2 = sklearn.metrics.average_precision_score(final_y[:,2],final_pred[:,2])\n",
    "\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "            ax1 = fig.add_subplot()\n",
    "            base_x = np.array([0,1])\n",
    "            nor_base_y = np.array([round(data.normal_size/data.test_len,3),round(data.normal_size/data.test_len,3)])\n",
    "            mci_base_y = np.array([round(data.mci_size/data.test_len,3),round(data.mci_size/data.test_len,3)])\n",
    "            ad_base_y = np.array([round(data.ad_size/data.test_len,3),round(data.ad_size/data.test_len,3)])\n",
    "            line1=ax1.plot(re_graph, pre_graph, label='Normal vs Others, AUC: '+str(round(auc_pr,3)), color='red')\n",
    "            line2=ax1.plot(re_graph1, pre_graph1, label='MCI vs Others, AUC: '+str(round(auc_pr1,3)), color='blue')\n",
    "            line3=ax1.plot(re_graph2, pre_graph2, label='Dementia vs Others, AUC: '+str(round(auc_pr2,3)), color='green')\n",
    "            line4=ax1.plot(base_x,nor_base_y,linestyle='--', color='red', label='Normal baseline, AUC: '+str(round(data.normal_size/data.test_len,3)))\n",
    "            line5=ax1.plot(base_x,mci_base_y,linestyle='--', color='blue', label='MCI baseline, AUC: '+str(round(data.mci_size/data.test_len,3)))\n",
    "            line6=ax1.plot(base_x,ad_base_y,linestyle='--', color='green', label='Dementia baseline, AUC: '+str(round(data.ad_size/data.test_len,3)))\n",
    "            #ax2.set_ylabel('Accuracy')\n",
    "            ax1.set_xlabel('Recall')\n",
    "            ax1.set_ylabel('Precision')\n",
    "            lines = line1 + line2 + line3 + line4 + line5 + line6\n",
    "            labels = [l.get_label() for l in lines]\n",
    "            ax1.legend(lines, labels, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "            plt.grid(True)\n",
    "            print(\"Normal AP: \",round(auc_pr,3))\n",
    "            print(\"MCI AP: \",round(auc_pr1,3))\n",
    "            print(\"Dementia AP: \",round(auc_pr2,3))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            random_roc_x = np.array([0,1])\n",
    "            random_roc_y = np.array([0,1])\n",
    "            fpr, tpr, thresholds_roc = sklearn.metrics.roc_curve(final_y[:,0],final_pred[:,0])\n",
    "            auc_roc = sklearn.metrics.roc_auc_score(final_y[:,0],final_pred[:,0])\n",
    "            fpr1, tpr1, thresholds_roc1 = sklearn.metrics.roc_curve(final_y[:,1],final_pred[:,1])\n",
    "            auc_roc1 = sklearn.metrics.roc_auc_score(final_y[:,1],final_pred[:,1])\n",
    "            fpr2, tpr2, thresholds_roc2 = sklearn.metrics.roc_curve(final_y[:,2],final_pred[:,2])\n",
    "            auc_roc2 = sklearn.metrics.roc_auc_score(final_y[:,2],final_pred[:,2])\n",
    "\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "            ax1 = fig.add_subplot()\n",
    "            line1=ax1.plot(fpr, tpr, label='Normal vs Others, AUC: '+str(round(auc_roc,3)), color='red')\n",
    "            line2=ax1.plot(fpr1, tpr1, label='MCI vs Others, AUC: '+str(round(auc_roc1,3)), color='blue')\n",
    "            line3=ax1.plot(fpr2, tpr2, label='Dementia vs Others, AUC: '+str(round(auc_roc2,3)), color='green')\n",
    "            line4=ax1.plot(random_roc_x,random_roc_y, label='Baseline, AUC: '+str(0.5),linestyle = '--', color='black')\n",
    "            #ax2.set_ylabel('Accuracy')\n",
    "            ax1.set_xlabel('False Positive Rate')\n",
    "            ax1.set_ylabel('True Positive Rate')\n",
    "            lines = line1 + line2 + line3 + line4\n",
    "            labels = [l.get_label() for l in lines]\n",
    "            ax1.legend(lines, labels, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "            plt.grid(True)\n",
    "            print(\"Normal AUC: \",round(auc_roc,3))\n",
    "            print(\"MCI AUC: \",round(auc_roc1,3))\n",
    "            print(\"Dementia AUC: \",round(auc_roc2,3))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print(\"-----------------\")\n",
    "         \n",
    "            #print(\"test_average_loss\",loss_sum)\n",
    "            try:\n",
    "                recall_normal = 100*recall/q\n",
    "                print(\"Normal_sensitivity\", round(recall_normal,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                precision_normal = 100*precision/w\n",
    "                print(\"Normal_precision\", round(precision_normal,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                specificity_normal = 100*specificity/e\n",
    "                print(\"Normal_specificity\", round(specificity_normal,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                F1_normal = 2*recall_normal*precision_normal/(recall_normal+precision_normal)\n",
    "                print('Normal_F1-score', round(F1_normal,1))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print(\"-----------------\")\n",
    "            #print(\"test_average_loss\",loss_sum)\n",
    "            try:\n",
    "                recall_mci = 100*recall1/q1\n",
    "                print(\"MCI_sensitivity\", round(recall_mci,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                precision_mci = 100*precision1/w1\n",
    "                print(\"MCI_precision\", round(precision_mci,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                specificity_mci = 100*specificity1/e1\n",
    "                print(\"MCI_specificity\", round(specificity_mci,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                F1_mci = 2*recall_mci*precision_mci/(recall_mci+precision_mci)\n",
    "                print('MCI_F1-score', round(F1_mci,1))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print(\"-----------------\")\n",
    "            #print(\"test_average_loss\",loss_sum)\n",
    "            try:\n",
    "                recall_ad = 100*recall2/q2\n",
    "                print(\"AD_sensitivity\", round(recall_ad,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                precision_ad = 100*precision2/w2\n",
    "                print(\"AD_precision\", round(precision_ad,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                specificity_ad = 100*specificity2/e2\n",
    "                print(\"AD_specificity\", round(specificity_ad,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                F1_ad = 2*recall_ad*precision_ad/(recall_ad+precision_ad)\n",
    "                print('AD_F1-score', round(F1_ad,1))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print(\"-----------------\")\n",
    "            try:\n",
    "                temp_accuracy = 100*accuracy_sum/len(X_test)\n",
    "                print(\"Total_Accuracy\", round(temp_accuracy,1))\n",
    "            except:\n",
    "                pass\n",
    "            print(\"-----------------\")\n",
    "            #print(\"test_average_loss\",loss_sum)\n",
    "            try:\n",
    "                macro_recall = (recall_normal + recall_mci + recall_ad)/3\n",
    "                print(\"Macro_sensitivity\", round(macro_recall,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                macro_precision = (precision_normal + precision_mci + precision_ad)/3\n",
    "                print(\"Macro_precision\", round(macro_precision,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                macro_specificity = (specificity_normal + specificity_mci + specificity_ad)/3\n",
    "                print(\"Macro_specificity\", round(macro_specificity,1))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                macro_F1 = 2*macro_recall*macro_precision/(macro_recall+macro_precision)\n",
    "                print('Macro_F1-score', round(macro_F1,1))\n",
    "            except:\n",
    "                pass\n",
    "            print(\"-----------------\")\n",
    "            print(A)\n",
    "            \n",
    "            loss_sum=loss_sum/(batch+1)\n",
    "            accuracy_list.append(temp_accuracy/100)\n",
    "            roc_normal_list.append(round(auc_roc,3))\n",
    "            roc_mci_list.append(round(auc_roc1,3))\n",
    "            roc_ad_list.append(round(auc_roc2,3))\n",
    "            test_list.append(loss_sum)\n",
    "            print(\"test_average_loss\",loss_sum)\n",
    "        \n",
    "        if temp_accuracy > accuracy:\n",
    "            accuracy = temp_accuracy\n",
    "            #torch.save(model,\"Resnet_\"+str(accuracy)+\".pt\")\n",
    "    time_steps = list(range(1, len(training_list) + 1))\n",
    "\n",
    "    # Plot the learning curve\n",
    "    for i in range(len(training_list)):\n",
    "        training_list[i] = training_list[i].cpu().detach().numpy()\n",
    "        test_list[i] = test_list[i].cpu().detach().numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax1 = fig.add_subplot()\n",
    "    line1=ax1.plot(time_steps, training_list, label='Training Loss',color='red')\n",
    "    line2=ax1.plot(time_steps, test_list, label='Test Loss',color='blue')\n",
    "    ax2 = plt.twinx()\n",
    "    line3=ax2.plot(time_steps, roc_normal_list, label='AUC_Normal',color='green')\n",
    "    line4=ax2.plot(time_steps, roc_mci_list, label='AUC_MCI',color='orange')\n",
    "    line5=ax2.plot(time_steps, roc_ad_list, label='AUC_AD',color='gray')\n",
    "    line6=ax2.plot(time_steps, accuracy_list, label='Accuracy',color='brown')\n",
    "    #ax2.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    lines = line1 + line2 + line3 + line4 + line5 + line6\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper left', bbox_to_anchor=(1.1, 1))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(\"Done!\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
